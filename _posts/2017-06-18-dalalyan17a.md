---
title: 'Further and stronger analogy between sampling and optimization: Langevin Monte
  Carlo and gradient descent'
abstract: In this paper, we revisit the recently established theoretical guarantees
  for the convergence of the Langevin Monte Carlo algorithm of sampling from a smooth
  and (strongly) log-concave density. We improve the existing results when the convergence
  is measured in the Wasserstein distance and provide further insights on the very
  tight relations between, on the one hand, the Langevin Monte Carlo for sampling
  and, on the other hand, the gradient descent for optimization. Finally, we also
  establish guarantees for the convergence of a version of the Langevin Monte Carlo
  algorithm that is based on noisy evaluations of the gradient.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: dalalyan17a
month: 0
tex_title: 'Further and stronger analogy between sampling and optimization: Langevin
  Monte Carlo and gradient descent'
firstpage: 678
lastpage: 689
page: 678-689
order: 678
cycles: false
author:
- given: Arnak
  family: Dalalyan
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/dalalyan17a/dalalyan17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

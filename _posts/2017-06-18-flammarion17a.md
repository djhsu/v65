---
title: Stochastic Composite Least-Squares Regression with Convergence Rate $O(1/n)$
abstract: We consider the minimization of composite objective functions composed of
  the expectation of quadratic functions and an arbitrary convex function. We study
  the stochastic dual averaging algorithm with a constant step-size, showing that
  it leads to a convergence rate of O(1/n) without strong convexity assumptions. This
  thus extends earlier results on least-squares regression with the Euclidean geometry
  to (a) all convex regularizers and constraints, and (b) all geometries represented
  by a Bregman divergence. This is achieved by a new proof technique that relates
  stochastic and deterministic recursions
layout: inproceedings
series: Proceedings of Machine Learning Research
id: flammarion17a
month: 0
tex_title: Stochastic Composite Least-Squares Regression with Convergence Rate $O(1/n)$
firstpage: 831
lastpage: 875
page: 831-875
order: 831
cycles: false
author:
- given: Nicolas
  family: Flammarion
- given: Francis
  family: Bach
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/flammarion17a/flammarion17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

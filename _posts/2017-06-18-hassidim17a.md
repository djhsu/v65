---
title: Submodular Optimization under Noise
abstract: We consider the problem of maximizing a monotone submodular function under
  noise.  Since the 1970s there has been a great deal of work on optimization of submodular
  functions under various constraints, resulting in algorithms that provide desirable
  approximation guarantees.  In many applications, however, we do not have access
  to the submodular function we aim to optimize, but rather to some erroneous or noisy
  version of it.  This raises the question of whether provable guarantees are obtainable
  in the presence of error and noise. We provide initial answers by focusing on the
  problem of maximizing a monotone submodular function under a cardinality constraint
  when given access to a noisy oracle of the function.  We show that there is an algorithm
  whose approximation ratio is arbitrarily close to the optimal $1-1/e$ when the cardinality
  is sufficiently large.  The algorithm can be applied in a variety of related problems
  including maximizing approximately submodular functions, and optimization with correlated
  noise.  When the noise is adversarial we show that no non-trivial approximation
  guarantee can be obtained.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hassidim17a
month: 0
tex_title: Submodular Optimization under Noise
firstpage: 1069
lastpage: 1122
page: 1069-1122
order: 1069
cycles: false
author:
- given: Avinatan
  family: Hassidim
- given: Yaron
  family: Singer
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/hassidim17a/hassidim17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

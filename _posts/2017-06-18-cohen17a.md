---
title: Tight Bounds for Bandit Combinatorial Optimization
abstract: We revisit the study of optimal regret rates in bandit combinatorial optimization—a
  fundamental framework for sequential decision making under uncertainty that abstracts
  numerous combinatorial prediction problems. We prove that the attainable regret
  in this setting grows as $\widetildeΘ(k^3/2\sqrt{d}T)$ where $d$ is the dimension
  of the problem and $k$ is a bound over the maximal instantaneous loss, disproving
  a conjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal
  rate should be of the form $\widetildeΘ(k\sqrt{d}T)$. Our bounds apply to several
  important instances of the framework, and in particular, imply a tight bound for
  the well-studied bandit shortest path problem. By that, we also resolve an open
  problem posed by Cesa-Bianchi and Lugosi (2012).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cohen17a
month: 0
tex_title: Tight Bounds for Bandit Combinatorial Optimization
firstpage: 629
lastpage: 642
page: 629-642
order: 629
cycles: false
author:
- given: Alon
  family: Cohen
- given: Tamir
  family: Hazan
- given: Tomer
  family: Koren
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/cohen17a/cohen17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

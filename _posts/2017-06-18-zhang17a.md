---
title: 'Empirical Risk Minimization for Stochastic Convex Optimization: $O(1/n)$-
  and $O(1/n^2)$-type of Risk Bounds'
abstract: Although there exist plentiful theories of empirical risk minimization (ERM)
  for supervised learning, current theoretical understandings of ERM for a related
  problem—stochastic convex optimization (SCO), are limited. In this work, we strengthen
  the realm of ERM for SCO by exploiting smoothness and strong convexity conditions
  to improve the risk bounds. First, we establish an $\widetildeO(d/n + \sqrtF_*/n)$
  risk bound when the random function is nonnegative, convex and smooth, and the expected
  function is Lipschitz continuous, where $d$ is the dimensionality of the problem,
  $n$ is the number of samples, and $F_*$ is the minimal risk. Thus, when $F_*$ is
  small we obtain an $\widetildeO(d/n)$ risk bound, which is analogous to the $\widetildeO(1/n)$
  optimistic rate of ERM for supervised learning. Second, if the objective function
  is also $λ$-strongly convex, we prove an $\widetildeO(d/n  + κF_*/n )$ risk bound
  where $κ$ is the condition number, and improve it to $O(1/[λn^2] + κF_*/n)$ when
  $n=\widetildeΩ(κd)$. As a result, we obtain an $O(κ/n^2)$ risk bound under the condition
  that $n$ is large and $F_*$ is small, which to the best of our knowledge, is the
  first $O(1/n^2)$-type of risk bound of ERM. Third, we stress that the above results
  are established in a unified framework, which allows us to derive new risk bounds
  under weaker conditions, e.g., without convexity of the random function.  Finally,
  we demonstrate that to achieve an $O(1/[λn^2] + κF_*/n)$ risk bound for supervised
  learning,  the $\widetildeΩ(κd)$ requirement on $n$ can be replaced with $Ω(κ^2)$,
  which is dimensionality-independent.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhang17a
month: 0
tex_title: 'Empirical Risk Minimization for Stochastic Convex Optimization: ${O}(1/n)$-
  and ${O}(1/n^2)$-type of Risk Bounds'
firstpage: 1954
lastpage: 1979
page: 1954-1979
order: 1954
cycles: false
author:
- given: Lijun
  family: Zhang
- given: Tianbao
  family: Yang
- given: Rong
  family: Jin
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/zhang17a/zhang17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

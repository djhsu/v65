---
title: Fast and robust tensor decomposition with applications to dictionary learning
abstract: " We develop fast spectral algorithms for tensor decomposition that match
  the robustness guarantees of the best known polynomial-time algorithms for this
  problem based on the sum-of-squares (SOS) semidefinite programming hierarchy. Our
  algorithms can decompose a 4-tensor with $n$-dimensional orthonormal components
  in the presence of error with constant spectral norm (when viewed as an $n^2$-by-$n^2$
  matrix).  The running time is $n^5$ which is close to linear in the input size $n^4$.
  We also obtain algorithms with similar running time to learn sparsely-used orthogonal
  dictionaries even when feature representations have constant relative sparsity and
  non-independent coordinates. The only previous polynomial-time algorithms to solve
  these problem are based on solving large semidefinite programs.  In contrast, our
  algorithms are easy to implement directly and are based on spectral projections
  and tensor-mode rearrangements. Or work is inspired by recent of Hopkins, Schramm,
  Shi, and Steurer (STOCâ€™16) that shows how fast spectral algorithms can achieve the
  guarantees of SOS for average-case problems.  In this work, we introduce general
  techniques to capture the guarantees of SOS for worst-case problems. "
layout: inproceedings
series: Proceedings of Machine Learning Research
id: schramm17a
month: 0
tex_title: Fast and robust tensor decomposition with applications to dictionary learning
firstpage: 1760
lastpage: 1793
page: 1760-1793
order: 1760
cycles: false
author:
- given: Tselil
  family: Schramm
- given: David
  family: Steurer
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/schramm17a/schramm17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---

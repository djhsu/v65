---
title: Multi-Observation Elicitation
abstract: We study loss functions that measure the accuracy of a prediction based
  on multiple data points simultaneously. To our knowledge, such loss functions have
  not been studied before in the area of property elicitation or in machine learning
  more broadly. As compared to traditional loss functions that take only a single
  data point, these multi-observation loss functions can in some cases drastically
  reduce the dimensionality of the hypothesis required. In elicitation, this corresponds
  to requiring many fewer reports; in empirical risk minimization, it corresponds
  to algorithms on a hypothesis space of much smaller dimension. We explore some examples
  of the tradeoff between dimensionality and number of observations, give some geometric
  characterizations and intuition for relating loss functions and the properties that
  they elicit, and discuss some implications for both elicitation and machine-learning
  contexts.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: casalaina-martin17a
month: 0
tex_title: Multi-Observation Elicitation
firstpage: 449
lastpage: 464
page: 449-464
order: 449
cycles: false
author:
- given: Sebastian
  family: Casalaina-Martin
- given: Rafael
  family: Frongillo
- given: Tom
  family: Morgan
- given: Bo
  family: Waggoner
date: 2017-06-18
address: 
publisher: PMLR
container-title: Proceedings of the 2017 Conference on Learning Theory
volume: '65'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 6
  - 18
pdf: http://proceedings.mlr.press/v65/casalaina-martin17a/casalaina-martin17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
